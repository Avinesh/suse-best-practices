== About This Document

This document describes how to design and build a large and scalable
private cloud to provide *Infrastructure as a Service* (IaaS) based on
open source products and open APIs. Private cloud setups come with huge
advantages for both internet service providers and customers compared to
conventional IT setups. From a customer's point of view, running the own
workload inside a public cloud allows for business agility and a very
high level of flexibility. For service providers, public cloud setups
ideally allow to leverage the principle of the "economy of scale" so
that even with massively growing demand, it remains easy and convenient
to serve customers.

Together, by means of a public cloud environment, customers and
providers create a truly integrated and optimized enterprise, and
accelerate digital transformation across the business.

Large scale cloud platforms, such as the one that is subject of this document,
are designed and built to fulfill the requirements of a modern and
future-proof data center. In such an environment applications are created on virtual
machines or container-based, highly automated and with a fast life-cycle
(DevOps approach), not limited to specific uses cases.

This document gives a general view of the architecture and key aspects of
an IaaS platform based on SUSE products and specifically designed and
targeted for cloud native workloads running in a large environment. The
architecture is based on real world implementations deployed at several
enterprise customers and uses best practices from these setups.

=== Cloud Primer

The term "Cloud" is ubiquitous in the IT industry by now. Hence it
is important to define the term "Private Cloud" as it will
be used throughout this document.

==== Cloud Computing and Conventional Setups

Most conventional IT setups share the same basic design tenets. They are
typically very customer-specific. This means they were built for a certain
customer and only upon said customer's request. Usually, conventional
setups do not share resources with other setups; all resources present
in a conventional IT setup are usually available to the customer for
which the setup was originally created only.

Conventional IT setups come with a number of disadvantages for both the
Internet service provider and the customer. The most important aspects are listed below:

- Conventional setups come with very long lead times as they need to be
  planned and the required hardware must then be acquired. This usually takes
  several weeks.

- Conventional setups come with very high investment costs to customers
  for both the development of an actual software solution and the
  acquisition of hardware (including infrastructure hardware such as
  network switches or load-balancers).

- In conventional setups, service providers usually lock customers
  into a contract for several years, massively limiting the flexibility of the
  customer.

- Conventional setups usually have a rather low degree of automation. They
  require several manual steps to be performed both by the customer and the
  Internet service provider.

The basic concept of "Cloud Computing" was introduced several years ago
to do away with all these disadvantages of conventional setups. Clouds
enforce a certain role shift especially from the service provider's
point of view: Instead of serving individual customers with solutions
tailor-made to their demands, in clouds, the service provider
turns into a platform provider. A cloud provider's main responsibility
is to run and maintain a platform that makes computing, storage and
network resources available dynamically and on an on-demand principle to
arbitrary customers.

The following list contains a number of factors that are the very basic
design tenets of clouds:

- Cloud environments allow for seamless scale-out of the platform
  so that in case of resource shortage, it is easy for the provider to
  extend the amount of available resources.

- Cloud environments are based on the principle of API services
  and the ability to issue requests for resources to said API services
  using a defined and well-known protocol such as ReST. Using such APIs,
  arbitrary services can be implemented in clouds.

- Cloud environments decouple hard- and software and use Software
  Defined Networking (SDN) and Software Defined Storage (SDS). Because
  all core functionality is written in software and exists inside the
  platform itself, the manual configuration of infrastructure
  hardware such as networking switches becomes unnecessary.

- Cloud environments allow customers to service themselves based
  on SDN, SDS and the aforementioned APIs.

- Cloud environments come with a great level of automation from
  both the customers' and the provider's point of view. This allows to save
  a lot of time on tasks that, in conventional setups, need to be done manually.

Generally, running a public cloud forces an Internet service provider to
transform their business. Rather than providing individual services to individual customers, 
with public cloud, they provide an overarching platform that customers are free to use at 
their own discretion.

==== OpenStack as base for the cloud

By using software built for the sole purpose of running public clouds,
Internet Service Providers greatly improve the level of automation and
standardization they have in their platform. The OpenStack Cloud
Computing platform, combined with additional tools, allows enterprises
to launch a public cloud product quickly and conveniently. Over
the last few years, OpenStack has become the #1 Open Source solution to
run public clouds all over the world.

The key features of the OpenStack cloud computing software are, amongst
others, these:

- OpenStack has a well-proven track record of being the perfect solution
  for large public cloud environments; organizations such as the CERN or
  SAP use OpenStack for their cloud platforms

- OpenStack has the principle of well-documented, standardized, open APIs
  at the heart of its concept, allowing users to leverage the full power
  of the API principle

- OpenStack is 100% Open Source software licensed under the terms of the
  Apache License, effectively avoiding the dreadful vendor lock-in that
  comes along with most commercial products. Because COTS (_Commercial
  off-the-shelf_, i.e. general purpose) hardware can be used, there also
  is no vendor lock-in on the hardware side

- OpenStack does not require an internet service provider to trust the
  manufacturer of a software product blindly -- because of its nature as
  a true Open Source solution, the source code is open for everybody to
  audit and examine

- OpenStack is not dominated by individual vendors but by the OpenStack
  foundation, of which everybody can become a member

- OpenStack, thanks to its massive user and developer community, comes
  with a lot of great components and features, rendering operating the
  cloud and using its features a convenient task

- OpenStack supports multi-tenant setups, effectively allowing large
  numbers of customers using one and the same cloud platform

- OpenStack is made available by its developers to users free of charge,
  resulting in extremely low initial setup costs; also, license fees and
  license renewal costs do not apply

The SUSE OpenStack Cloud product is based on the upstream OpenStack project. It allows the 
operater to hanlde the complexitiy of the project and control the deployment, the dayly operation and 
maintanace of the platform. The integrated deployment tool allows an easy setup and deployment of
the complex infrastructure. The professional support of SUSE ensures that the a stable and available platform can be used,
which turns an opensource project in an enterprise grade software solution.

=== Scope Of This Documentation

It is of crucial importance to understand what this guide is supposed to
be and what it is not. The following paragraphs lay out the intention of
the document you are about to read.

==== Scope Definition

This document will, based on best practices, describe the most basic
design tenets of a cloud environment built for massive scale-out and a
very large target size. It will not provide specific implementation
details such as the required configuration for individual components.
It will help the reader to understand, which decisions are important 
in the design phase to create a scalable future proof cloud architecture.

As the details for such a design depends on a lot of parameters, the 
document is not able to provide the one and only solution - examples will 
show possibilities, and should help the reader to design it's own solution.

As such, this document does explicitly not aim to replace any document
made available by SUSE officially as documentation. There are various
reference documents available for SUSE OpenStack Cloud (SOC), SUSE
Enterprise Storage (SES, Ceph), SUSE Enterprise Linux (SLES), patch
concepts like SUSE Manager or the Subscriptions Management Tool (SMT),
the SUSE Enterprise Linux High Availability Extension (SLE HAE). Those
reading this document should be aware of reference documentation made
available by SUSE applicable to their respective setup

For implementation specific documentation, please have a look at the
documentation at https://www.suse.com/documentation. Here, you will find
for example the "Deployment", "Administrator" and "End User" guides for
SUSE Enterprise Storage and SUSE OpenStack Cloud. Details specific to a
certain customer, a certain environment or a certain business case are
generally determined by the customer and SUSE together during a "Design
and Implementation Workshop", see <<Implementation_Phases>> . Hence, they
are not dealt with in this document.


=== Target Audience

The target audience of this guide are decision makers and application-,
cloud- and network architects. After reading this document, the target
audience is expected to understand the basic architecture of large scale
clouds and how clouds can be used to solve their respective business
challenges.

==== IaaS, PaaS, Serverless: Operation models for apps in clouds

In cloud environments, providers typically have different offerings for
different requirements on the customers' side. These are generally
referred to as "as-a-Service"-offerings, such as Infrastructure as a
Service (IaaS), Platform as a Service (PaaS) or (Software as a Service).
In recent times, also "serverless computing" is a commonly used term.

All these terms describe models to operate particular environments and
applications inside a cloud computing environment. They are different in
particular when it comes to defining the provider's and the customer's
responsibilities for running the platform.

- *Infrastructure as a Service*: Here, the provider's sole job is to run
  and operate the platform to provide customers with arbitrary amounts
  of compute, storage and network resources. Running and managing actual
  apps in the platform is left to the cloud customer completely.

- *Platform as a Service*: In PaaS setups, the provider does not only
  offer virtual compute, storage and network resources as well as several
  integration tools to combine them properly. For instance, users needing
  a database can acquire a database with a few mouse clicks as result of
  a Database-as-a-Service offering instead of having to set-up a database
  in a virtual machine themselves.

- *Software as a Service*: This operation model describes a design where
  the cloud provider takes care of running the virtual machines and the
  actual application for the customers (which is why in a certain way,
  this operation model resembles "managed services" from the conventional
  world). The user is only consuming the service and does not care about
  the used infrastructure.

While OpenStack generally allows for all operation models mentioned due
to its versatility and flexibility, this document will focus on the
provider point of view and explain how customers can use SUSE OpenStack
Cloud to build seamlessly scalable, large cloud environments for IaaS
services.

.IT service consumation variants 
image::it-service-consumation-basics_v2.svg[align="center",width=400]

==== Private, Public, Hybrid

There are three ways for customers to consume services provided by cloud
setups:

- *Private Cloud*: A private cloud is generally run by a company for own
  purposes only. It is not available for usage to the wide public.

- *Public Cloud*: A public cloud environment is run by a company to offer
  compute, storage and network resources to the wide public, often giving
  users the opportunity to register an account themselves and start using
  the cloud services immediately.

- *Hybrid Cloud*: When following a hybrid cloud approach, customers use
  services offered by public cloud environments (such as Amazon AWS or
  Microsoft Azure) as well as services offered by an own private cloud.

The cloud setup described in this guide can generally serve as a public
cloud or a private cloud. Hybriod considerations are, however, not within
the scope of this document.

.Hybrid environments combine the advantages of public and private clouds.
image::hybrid-computing.png[align="center",width=400]

==== Compute, Storage, Network

The three main aspects of IaaS are Compute, Storage and Network. Each of
these deserves a separate discussion in the context of a large cloud --
hence, this technical guide will elaborate on all factors in separate in
the this document's chapters. The minimum viable product assumed to be
the desired result is a virtual machine with attached block-storage that
has working connectivity to the internet, with all of these components
being provided virtualized or software-defined.

=== The Design Principles

Although every business is unique and every customer comes with unique
requirements, there is a small set of basic requirements that all cloud
environments have in common.

To build your IaaS solution, you will need at least these resources:

- Hardware (standard industry servers, Commercial off-the-shelf [COTS])
to run the cloud, control servers, admin servers and host storage.
Commodity hardware (one or two different types for the whole platform)
is used for cost efficiency.

- Standard OSI Layer 2 network hardware

- Open source software to provide basic cloud functionality to realize
the IaaS offering, including software defined networking (SDN), the
operating system for said servers and a solution fot software defined
storage (SDS).

==== Design principles, goals and features

The following list describes the basic design tenets that were taken
into consideration while designing the massively scalable cloud that is
the subject of this guide.

NOTE: The details of implementing the following design principles for
the individual aspects of the cloud setup (Compute, Network, Storage)
will be the subject in the aspect's chapter respectively.

- Scalability: At any point in time, it must be possible to extend the
  cloud's resources by adding additional nodes for compute or storage
  purposes

- Resiliance: The cloud service must be robust and fault-tolerant. A concept
  for High Availability must be in place. 

- Standardization: Open standards, Open Source software, open APIs that
  are well documented and commodity hardware (COTS) allow for very high
  flexibility and help to avoid vendor lock-ins.

- The old world and the new world: The platform must be able to handle
  cloud-native applications as well as traditional or legacy workloads,
  with a clear focus on cloud native applications. 

Some examples for typical workloads that may be found on a platform like
the one explained in this guide are:

- Traditional root VMs (hosted)
- Orchestrated applications (cloud optimized)
- Cloud native workloads, e.g. BOSH (for a Cloud Foundry based PaaS
  solution) or container-based solutions

.Container-based workloads such as CaaS by SUSE work perfectly on top of cloud environments
image::container-on-top.png[align="center",width=300]

==== Workload types for Cloud environments

Cloud computing has fundamentally changed the way how applications are
rolled out for production use. While conventional applications typically
follow a monolithic approach, modern applications built according to
agile standards are based on numerous little components, the so called
"micro services". This document refers to conventional apps generally as
"traditional" and to apps following the new paradigm as "cloud native".

There are, however, applications or workloads that do not fit perfectly
into either of these categories. effectively creating a twilight zone in
which special requirements exist. Traditional applications (i.e. legacy
workloads, sometimes also referred to as 'pets' or 'kitten') are for
sure not to disappear anytime soon -- hence, any given IaaS platform
must be able to deal with traditional workloads and of course also with
cloud-native workloads. The necessity to store data permanently is one
of the biggest challenges in that context.

Generally speaking, an IaaS platform such as SUSE OpenStack Cloud is
optimized for "cloud native" workloads and allows these to leverage the
existing functionality the best possible way. Running such cloud native
workloads on a SOC platform means the following for the service:

* Stateless: The service stores no local data and can be restarted at any time. All data has to be stored externally in an data store
* Automated: The installation of the server is automated and no manual configuration is needed
* Scale out: More performance of the application can be achieved by starting (adding) new instances
* Availability: The availability of a service depends on his redundancy.

Applications that do not follow the "cloud native"-approach will work in
a public cloud environment but will not leverage most of the platforms'
features. SUSE OpenStack Cloud offers an option to 
include hypervisors also in a HA configuration. A failure of a hypervisor 
will be detected and the died instances will be restarted on remainig hypervisors.
This helps to opeerate traditional workloads in a "cloud native" optimized environment.


=== Business Drivers and Use Cases

Many businesses in all industries and application segments are enforcing
the adoption of cloud principles in their environments. And while the
reasons for that are as diverse as the customers themselves, there are a
few common goals that most enterprises share. The main motivation is the
need

- For more flexibility in the own IT setup
- For a higher level of automation
- For competitive innovation
- For lower times-to-market when creating new products and applications
- For the migration of legacy application and workloads
- To identify disposable components in the own environment
- To accelarete the own growth and performance
- To reduce IT costs (CAPEX/OPEX).

All these factors play a vibrant role in the decision to deliver services
in a cloud-native-manner and move more applications to the cloud per se.

=== Bimodal IT

Modern IT companies have developed a way of working that allows them to
be agile and quick when developing new features and yet protect existing
processes and systems, which may be of crucial importance for the company
as such. Often, such historically grown processes and systems cannot be
replaced at ease or at all. By following such a model of two speeds --
being agile and innovative on the one hand and protecting existing and
critical infrastructure at the other hand -- companies can meet the needs
of today's fast-paced IT industry. This is what many refer to as "Bimodal
IT".

In said scheme, Mode 1 is responsible for providing enterprise-class IT
at constant speeds (traditional workloads, "legacy") and Mode 2 is to
develop and deliver cloud-native applications using principles such as
CI/CD at high velocity. Truly successful are such companies that deliver
on both items in the best optimized way. The IaaS platform outlined in
this document supports companies by being a solution for both needs. The
companies deploying such a solution will benefit from

- A highly cost-effective, rapidly responsible and elastic IT that is
  very well aligned with its actual businees needs in order to support
  the bimodal IT operations model

- A large portfolio of business and IT services that effectively
  leverage the best features provided by the underlying IaaS solution,
  allowing for seamless flexibility (applications can be built exactly
  as necessary and run wherever they are required)

- The ability to map business processes to applications

- The ability to innovate faster while leveraging already-existing
  servers and capabilities, allowing for very short times-to-market

==== Cloud Use Cases

This document explains how service providers (privat / public)  build and operate a cloud
designed to meet the needs of both Mode 1 and Mode 2 IT. Possible ways
to use an environment like the one described in this document are:

- The provisioning of an IaaS layer for enterprise and cloud providers
- PaaS and SaaS offerings
- Allowing Cloud Service Providers (CSP) the usage, marketing and
  Selling of own services on top of the existing IaaS layer
- The increase of automation in the own environment based on the cloud
  orchestration services
- Provisioning infrastructure for DevOps and agile environments (CI)

It is important to note though that each of the mentioned scenarios has
a specific business case behind it and that companies need to very well
think about the solution they want to provide before they start building
it. Depending on the use case, there will be minimal differences that
lead to great effects once the solution is in place -- and even smallest
design decisions directly influence how well the platform is suited for
what it is expected to do. Getting help from experts on this subject is
generally a good idea and recommended.

==== SLA considerations

When planning a cloud and determining your use case, it is also helpful
to think about the SLA that the platform will be expected to deliver on
as early as possible. To define a proper SLA, the functionality of the
platform must be clear and understood. But the provider running the
cloud will also have to define what kind of provider he wants to be --
for instance, all major public cloud providers clearly distinct between
their work (which is providing a working platform) and anything that the
customers might do on it. For the latter part of the work, the customer
bears the sole responsibility.

Of course, the answer to this question also depends on the kind of cloud
that is supposed to be created. Private clouds constructed for specific
use cases will typically face other requirements than large clouds made
available to the public.

NOTE: A cloud will always take the control services in the focus
of the SLA - The running workload on top of a hypervisor is in the 
responsibility of the user - and mostly not part of the SLA.
// vim:set syntax=asciidoc:
